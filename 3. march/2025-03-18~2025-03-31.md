# 🚀 개인 프로젝트 진행 및 CNN 모델 연구  

> 3월 18일부터 개인 프로젝트를 시작하여, 3월 31일까지 진행.  

---

## 📌 **프로젝트 진행**  
1. **EDA (탐색적 데이터 분석)**  
2. **데이터 전처리**  
3. **CNN 모델 설계**  
4. **모델 학습**  
5. **성능 평가 및 시각화 → 오버피팅 확인**  
6. **다양한 모델 실험 & 하이퍼파라미터 튜닝 (ResNet, VGG, GoogLeNet 비교)**  
7. **모델 성능 분석**  
8. **모델 성능 향상**
9. **DB**
10. streamlit 대시보드 시각화

---

## 🔍 **1. EDA (Exploratory Data Analysis)**  
- **데이터셋 구조 확인** (클래스 개수, 이미지 개수)  
- **결측치 및 이상치 확인**  
- **이미지 크기 분석** (일관성 체크)  
- **클래스별 RGB 히스토그램 분석** → 아직 활용법 고민 중 🤔  
- **데이터 불균형 분석**  

**💡 대표적인 CNN 모델 종류**  
팀원이 추천한 CNN 모델 정리 링크 참고하여 모델 탐색 중.  

---

## 💾 **2. 모델 저장 방식 (PyTorch)**  
PyTorch에서 모델 저장 방식은 **세 가지**가 있음.  

### ** 1. `state_dict` 저장 (추천)**
- 모델이 학습된 가중치만 저장하는 방식으로, 가장 일반적으로 사용됨.  
- 모델 구조를 유지하면서 가중치만 저장 가능하여 재사용이 용이함.  
```
torch.save(model.state_dict(), 'model_state_dict.pt')
loaded_model = Model()
loaded_model.load_state_dict(torch.load('model_state_dict.pt'))
```

### ** 2. 모델을 통째로 저장 (지양)**  
- 모델 클래스의 코드가 변경되면 불러올 수 없는 문제가 발생할 수 있음.  
- 다만, 학습 과정 기록(history.json) 저장 시에는 유용함.  

```
torch.save(model, 'model_state_dict.pt')
loaded_model = torch.load('model_state_dict.pt')
```

### ** 3. TorchScript로 저장**  
- 모델을 `.pt` 형식으로 저장하여 배포 시 유용함.  
- 추론 속도를 높이거나, PyTorch 비지원 환경에서 사용하고자 할 때 활용 가능.  
```
model_scripted = torch.jit.script(model)
model_scripted.save('model_state_dict.pt')
loaded_model = torch.jit.load('model_state_dict.pt')
```
---

## 📈 **3. 학습 기록 저장 (히스토리 vs 손실 함수 저장)**  
- **손실 함수(Loss)만 저장** → 학습 과정의 손실값만 저장됨.  
- **히스토리(History) 저장** → 손실값뿐만 아니라 Accuracy 등 다양한 정보를 포함하여 저장됨.  
- 비교 분석을 위해 히스토리 저장이 더 유용함.  

---

## 🔄 **4. 여러 개의 모델 비교 시 고려할 점**  
- **입력 크기 통일**  
- **Feature Extractor 구조 통일**  
- **출력층(Output Layer) 통일**  
- **손실 함수 및 최적화 기법 통일**  

동일한 기준에서 비교해야 의미 있는 실험 결과를 얻을 수 있음.  

---

## 🔁 **5. Overfitting 이슈 및 대응 전략**

- 초기 학습에서 **Train Accuracy는 상승하는 반면, Validation Accuracy는 정체**되는 현상이 나타남 → **과적합(Overfitting)** 의심.
- 이를 해결하기 위해 다음과 같은 전략들을 실험함:
    - **Dropout (0.5)**: Fully Connected Layer에 적용해 과적합 방지
    - **Data Augmentation**: `RandomFlip`, `RandomRotation`, `ColorJitter` 등 적용
    - **EarlyStopping**: `patience=10`, `max_epoch=100` 설정하여 모델이 성능 개선이 없는 경우 조기 종료
    - **Fine-tuning**: ResNet, VGG의 Feature Extractor 일부에 `requires_grad=True` 적용하여 미세 조정

---

## 🧠 **6. 다양한 모델 실험 및 성능 비교**

- 실험에 사용한 모델:
    
    
    | 모델 | 특징 | 성능 (Test Acc.) |
    | --- | --- | --- |
    | `Custom CNN` | 구조 직접 설계, 간단한 구조 | **98.80%** |
    | `ResNet50` | Skip Connection 활용, 안정적인 성능 | 98.51% → **Fine-tuning 후 상승** |
    | `VGG16` | 단순하고 해석이 쉬운 구조 | 95.84% → Fine-tuning 후 **98.93%** |
    | `MobileNetV2` | 경량 모델, 빠른 추론 | 초기 95% → Fine-tuning 후 **99.89%** |
- **동일한 구조와 하이퍼파라미터 설정**으로 실험하여 **정량적 비교** 가능하도록 구성

---

## 🤝 **7. 앙상블 적용 및 성능 향상**

- 모델을 여러 번 돌릴 때마다 결과 편차가 컸고, 정확도가 **100%**에 도달하기도 했음 → **단일 모델 과적합 가능성 고려**
- 이에 따라 3개 모델(`ResNet50`, `VGG16`, `MobileNetV2`)의 결과를 평균내는 **Soft Voting 방식의 앙상블**을 적용
- **Confusion Matrix 기준, 모든 클래스에서 완벽 분류 달성 (정확도 100%)**

---

## 🧮 **8. 실시간 로깅 및 MongoDB 연동**

- 학습 시 에폭별 로그를 `MongoDB`에 저장하여 실시간 분석 가능
- 저장 구조:
    - `trainings`: 모델 단위 메타 정보
    - `epochs`: 에폭별 loss, acc, 시간 등
    - `status`: 학습 상태 관리 (in_progress → completed)
- **MongoDB를 선택한 이유**:
    - 이전까지 RDS나 SQLite만 사용 → 새로운 경험을 위해 NoSQL 채택
    - 스키마 유연성 덕분에 모델별로 구조가 달라도 저장이 용이
    - Streamlit 연동도 간편하고, 빠르게 클라우드 기반 실시간 대시보드를 구현할 수 있음

---

## 📊 **9. 시각화 및 Streamlit 대시보드 구현**

- `MongoDB`에서 실시간 데이터를 읽어 Streamlit으로 시각화
- 구현한 주요 기능:
    - 모델별 성능 요약
    - epoch별 학습 추이 (loss/acc)
    - 학습 상태 표시 및 시간 필터링
- 실제 배포 링크: [📎 Streamlit 대시보드](https://model-tracker-bsmknozj45d9xndtbbeb4h.streamlit.app/#bd9568c6)

---

## 🧭 **10. 향후 계획 및 개선 방향**

- 🔍 **Grid Search**: 최적의 하이퍼파라미터 탐색 자동화
- 📦 **모델 비교 플랫폼(MCP)** 고도화 → 실험 자동 저장 및 정리
- 🌐 **FastAPI 연동** 및 `RESTful API`로 추론 시스템 확장
- 📄 보고서 자동 생성 기능 추가 (`Streamlit` 내 PDF 변환 고려)

---

### 참고 자료 및 링크 🔗
- [깃헙](https://github.com/sunnyanna0/model-tracker)
- [대시보드배포](https://model-tracker-bsmknozj45d9xndtbbeb4h.streamlit.app/#bd9568c6)